{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and modify it to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "IRIS_TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species']\n",
    "train_set=pd.read_csv(IRIS_TRAIN_URL,names=names,skiprows=1)\n",
    "test_set=pd.read_csv(IRIS_TEST_URL,names=names,skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_set.drop(columns=\"species\",axis=1)\n",
    "test_X=test_set.drop(columns=\"species\",axis=1)\n",
    "train_y=pd.get_dummies(train_set[\"species\"])\n",
    "test_y=pd.get_dummies(test_set[\"species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_train_network(n_nodes,iterations):\n",
    "    np.random.seed(100)\n",
    "    X=tf.placeholder(shape=(120,4),dtype=tf.float64,name=\"X\")\n",
    "    y=tf.placeholder(shape=(120,3),dtype=tf.float64,name=\"y\")\n",
    "    \n",
    "    #Weights for input layer and hidden layers\n",
    "    w1=tf.Variable(np.random.rand(4,n_nodes),dtype=tf.float64)\n",
    "#     b1=tf.Variable(np.random.rand(n_nodes),dtype=tf.float64)\n",
    "    \n",
    "    w2=tf.Variable(np.random.rand(n_nodes,n_nodes),dtype=tf.float64)\n",
    "#     b2=tf.Variable(np.random.rand(n_nodes),dtype=tf.float64)\n",
    "    \n",
    "    w3=tf.Variable(np.random.rand(n_nodes,3),dtype=tf.float64)\n",
    "#     b3=tf.Variable(np.random.rand(3),dtype=tf.float64)\n",
    "    \n",
    "    #create neural network graph\n",
    "    h1=tf.sigmoid(tf.matmul(X,w1))\n",
    "    h2=tf.sigmoid(tf.matmul(h1,w2))\n",
    "    \n",
    "    y_predict=tf.sigmoid(tf.matmul(h2,w3))\n",
    "    \n",
    "    #loss function\n",
    "    deltas=tf.square(y_predict-y)\n",
    "    loss=tf.reduce_sum(deltas)\n",
    "    \n",
    "    #Train operation to minimize loss\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.005)\n",
    "    train=optimizer.minimize(loss)\n",
    "    \n",
    "    #initialize variable and run session\n",
    "    init=tf.global_variables_initializer()\n",
    "    sess=tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    #Training of network\n",
    "    \n",
    "    for i in range(0,iterations):\n",
    "        sess.run(train,feed_dict={X:train_X,y:train_y})\n",
    "        loss_plot.append(sess.run(loss, feed_dict={X: train_X.as_matrix(), y: train_y.as_matrix()}))\n",
    "        weights1 = sess.run(w1)\n",
    "        weights2 = sess.run(w2)\n",
    "        weights3 = sess.run(w3)\n",
    "        if(i%10==0):\n",
    "            print(f\"{i}/{iterations}  loss= {loss_plot[-1]}\")\n",
    "#         print(\"loss (hidden nodes: %d, iterations: %d): %.2f\" % (10, iterations, loss_plot))\n",
    "#         sess.close()\n",
    "        \n",
    "    return weights1, weights2,weights3\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:40: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/4000  loss= 239.90878780667742\n",
      "10/4000  loss= 239.7463004179387\n",
      "20/4000  loss= 239.22544267631466\n",
      "30/4000  loss= 237.27286779240671\n",
      "40/4000  loss= 228.805492106476\n",
      "50/4000  loss= 192.69124905397462\n",
      "60/4000  loss= 117.59865630830897\n",
      "70/4000  loss= 79.8108426979995\n",
      "80/4000  loss= 82.45278193529137\n",
      "90/4000  loss= 77.96127423473689\n",
      "100/4000  loss= 72.53358990913188\n",
      "110/4000  loss= 66.86595439109013\n",
      "120/4000  loss= 60.0678077839803\n",
      "130/4000  loss= 53.4461716512707\n",
      "140/4000  loss= 48.048703471162625\n",
      "150/4000  loss= 43.90557946518729\n",
      "160/4000  loss= 40.72328941958456\n",
      "170/4000  loss= 38.14826655748535\n",
      "180/4000  loss= 35.80230202490242\n",
      "190/4000  loss= 33.526903708156354\n",
      "200/4000  loss= 31.23313689157952\n",
      "210/4000  loss= 28.905501961624353\n",
      "220/4000  loss= 26.574689200006844\n",
      "230/4000  loss= 24.283263419717294\n",
      "240/4000  loss= 22.082947991864337\n",
      "250/4000  loss= 20.029000161276734\n",
      "260/4000  loss= 18.164253878324626\n",
      "270/4000  loss= 16.508109792334118\n",
      "280/4000  loss= 15.058944885480983\n",
      "290/4000  loss= 13.802212056417096\n",
      "300/4000  loss= 12.71735061549105\n",
      "310/4000  loss= 11.78184856997942\n",
      "320/4000  loss= 10.973922717056212\n",
      "330/4000  loss= 10.27442500006755\n",
      "340/4000  loss= 9.66775152142391\n",
      "350/4000  loss= 9.141338588090342\n",
      "360/4000  loss= 8.684077064995837\n",
      "370/4000  loss= 8.285371692561991\n",
      "380/4000  loss= 7.9355385274498556\n",
      "390/4000  loss= 7.626397284899636\n",
      "400/4000  loss= 7.3513354899446455\n",
      "410/4000  loss= 7.105041311051053\n",
      "420/4000  loss= 6.883174575310582\n",
      "430/4000  loss= 6.681896054896781\n",
      "440/4000  loss= 6.496494628358497\n",
      "450/4000  loss= 6.320565011689887\n",
      "460/4000  loss= 6.156051474830272\n",
      "470/4000  loss= 6.009157316519607\n",
      "480/4000  loss= 5.876505622357543\n",
      "490/4000  loss= 5.755258503080922\n",
      "500/4000  loss= 5.643380397908127\n",
      "510/4000  loss= 5.5394311662998\n",
      "520/4000  loss= 5.4423653644988965\n",
      "530/4000  loss= 5.351352942441995\n",
      "540/4000  loss= 5.265722105404567\n",
      "550/4000  loss= 5.18491307263701\n",
      "560/4000  loss= 5.108452114901737\n",
      "570/4000  loss= 5.0359323958289774\n",
      "580/4000  loss= 4.967000565354076\n",
      "590/4000  loss= 4.901347106125051\n",
      "600/4000  loss= 4.838699063208006\n",
      "610/4000  loss= 4.778814404411987\n",
      "620/4000  loss= 4.721477540529815\n",
      "630/4000  loss= 4.666495715589191\n",
      "640/4000  loss= 4.6136960250196655\n",
      "650/4000  loss= 4.562922998451952\n",
      "660/4000  loss= 4.51403654073133\n",
      "670/4000  loss= 4.466910178519192\n",
      "680/4000  loss= 4.421429499241645\n",
      "690/4000  loss= 4.377490724450199\n",
      "700/4000  loss= 4.334999338889995\n",
      "710/4000  loss= 4.293868776523604\n",
      "720/4000  loss= 4.254019161914573\n",
      "730/4000  loss= 4.215376186993426\n",
      "740/4000  loss= 4.17787018986478\n",
      "750/4000  loss= 4.1414354932044795\n",
      "760/4000  loss= 4.106009999285231\n",
      "770/4000  loss= 4.0715350122690666\n",
      "780/4000  loss= 4.037955177226808\n",
      "790/4000  loss= 4.00521846055763\n",
      "800/4000  loss= 3.973276097700167\n",
      "810/4000  loss= 3.9420824802704724\n",
      "820/4000  loss= 3.9115949915257984\n",
      "830/4000  loss= 3.881773794887051\n",
      "840/4000  loss= 3.8525816060916944\n",
      "850/4000  loss= 3.8239834668457577\n",
      "860/4000  loss= 3.795946532395676\n",
      "870/4000  loss= 3.768439880689969\n",
      "880/4000  loss= 3.741434342366712\n",
      "890/4000  loss= 3.7149023510564585\n",
      "900/4000  loss= 3.6888178166088244\n",
      "910/4000  loss= 3.663156010483691\n",
      "920/4000  loss= 3.637893466417463\n",
      "930/4000  loss= 3.613007892396097\n",
      "940/4000  loss= 3.5884780949443664\n",
      "950/4000  loss= 3.564283908762488\n",
      "960/4000  loss= 3.5404061365526225\n",
      "970/4000  loss= 3.516826497373705\n",
      "980/4000  loss= 3.493527578009883\n",
      "990/4000  loss= 3.470492793740721\n",
      "1000/4000  loss= 3.4477063545481474\n",
      "1010/4000  loss= 3.4251532375621783\n",
      "1020/4000  loss= 3.402819165753179\n",
      "1030/4000  loss= 3.380690592357036\n",
      "1040/4000  loss= 3.3587546894339404\n",
      "1050/4000  loss= 3.3369993441203913\n",
      "1060/4000  loss= 3.315413159492577\n",
      "1070/4000  loss= 3.293985461193431\n",
      "1080/4000  loss= 3.2727063086309127\n",
      "1090/4000  loss= 3.2515665099445155\n",
      "1100/4000  loss= 3.2305576429800515\n",
      "1110/4000  loss= 3.2096720793098648\n",
      "1120/4000  loss= 3.188903011453298\n",
      "1130/4000  loss= 3.168244482214841\n",
      "1140/4000  loss= 3.147691415947331\n",
      "1150/4000  loss= 3.1272396499323625\n",
      "1160/4000  loss= 3.1068859658225287\n",
      "1170/4000  loss= 3.0866281177578436\n",
      "1180/4000  loss= 3.066464858427\n",
      "1190/4000  loss= 3.04639596076132\n",
      "1200/4000  loss= 3.0264222327829158\n",
      "1210/4000  loss= 3.006545525844569\n",
      "1220/4000  loss= 2.986768732162262\n",
      "1230/4000  loss= 2.96709577650958\n",
      "1240/4000  loss= 2.947531592104527\n",
      "1250/4000  loss= 2.9280820894061863\n",
      "1260/4000  loss= 2.9087541095317713\n",
      "1270/4000  loss= 2.8895553676124246\n",
      "1280/4000  loss= 2.870494381853855\n",
      "1290/4000  loss= 2.8515803934739563\n",
      "1300/4000  loss= 2.8328232740131964\n",
      "1310/4000  loss= 2.8142334240549998\n",
      "1320/4000  loss= 2.795821662438848\n",
      "1330/4000  loss= 2.777599112328633\n",
      "1340/4000  loss= 2.759577080764308\n",
      "1350/4000  loss= 2.7417669352660625\n",
      "1360/4000  loss= 2.7241799817667913\n",
      "1370/4000  loss= 2.7068273451531466\n",
      "1380/4000  loss= 2.6897198531759283\n",
      "1390/4000  loss= 2.672867928226395\n",
      "1400/4000  loss= 2.6562814857387664\n",
      "1410/4000  loss= 2.6399698429726364\n",
      "1420/4000  loss= 2.6239416383556433\n",
      "1430/4000  loss= 2.608204763164924\n",
      "1440/4000  loss= 2.592766305692167\n",
      "1450/4000  loss= 2.5776325067285164\n",
      "1460/4000  loss= 2.5628087298422733\n",
      "1470/4000  loss= 2.5482994424893484\n",
      "1480/4000  loss= 2.534108209323537\n",
      "1490/4000  loss= 2.520237696550307\n",
      "1500/4000  loss= 2.506689686381158\n",
      "1510/4000  loss= 2.493465099980579\n",
      "1520/4000  loss= 2.4805640288948947\n",
      "1530/4000  loss= 2.4679857728002825\n",
      "1540/4000  loss= 2.455728882638695\n",
      "1550/4000  loss= 2.4437912080251936\n",
      "1560/4000  loss= 2.432169948107475\n",
      "1570/4000  loss= 2.420861704195712\n",
      "1580/4000  loss= 2.409862533648791\n",
      "1590/4000  loss= 2.399168004247022\n",
      "1600/4000  loss= 2.3887732477949344\n",
      "1610/4000  loss= 2.378673012788656\n",
      "1620/4000  loss= 2.368861715439501\n",
      "1630/4000  loss= 2.3593334887336015\n",
      "1640/4000  loss= 2.350082228905794\n",
      "1650/4000  loss= 2.3411016394579685\n",
      "1660/4000  loss= 2.3323852717447595\n",
      "1670/4000  loss= 2.323926563463032\n",
      "1680/4000  loss= 2.3157188736209813\n",
      "1690/4000  loss= 2.3077555146313724\n",
      "1700/4000  loss= 2.300029781213438\n",
      "1710/4000  loss= 2.29253497675389\n",
      "1720/4000  loss= 2.2852644366679167\n",
      "1730/4000  loss= 2.278211549119481\n",
      "1740/4000  loss= 2.271369773710826\n",
      "1750/4000  loss= 2.264732657021465\n",
      "1760/4000  loss= 2.2582938465338858\n",
      "1770/4000  loss= 2.252047102316283\n",
      "1780/4000  loss= 2.245986307049623\n",
      "1790/4000  loss= 2.240105474067561\n",
      "1800/4000  loss= 2.234398754034009\n",
      "1810/4000  loss= 2.228860440185511\n",
      "1820/4000  loss= 2.2234849722837113\n",
      "1830/4000  loss= 2.2182669395790793\n",
      "1840/4000  loss= 2.2132010825366915\n",
      "1850/4000  loss= 2.2082822938209166\n",
      "1860/4000  loss= 2.203505618474016\n",
      "1870/4000  loss= 2.1988662533884753\n",
      "1880/4000  loss= 2.194359546242284\n",
      "1890/4000  loss= 2.189980993964798\n",
      "1900/4000  loss= 2.185726240576702\n",
      "1910/4000  loss= 2.1815910748246665\n",
      "1920/4000  loss= 2.1775714274867917\n",
      "1930/4000  loss= 2.173663368343181\n",
      "1940/4000  loss= 2.1698631030193165\n",
      "1950/4000  loss= 2.16616696966721\n",
      "1960/4000  loss= 2.1625714354887586\n",
      "1970/4000  loss= 2.1590730932087903\n",
      "1980/4000  loss= 2.1556686574483797\n",
      "1990/4000  loss= 2.152354961038266\n",
      "2000/4000  loss= 2.1491289513776626\n",
      "2010/4000  loss= 2.1459876867824796\n",
      "2020/4000  loss= 2.142928332837264\n",
      "2030/4000  loss= 2.139948158826727\n",
      "2040/4000  loss= 2.137044534129969\n",
      "2050/4000  loss= 2.134214924792987\n",
      "2060/4000  loss= 2.1314568900818296\n",
      "2070/4000  loss= 2.1287680791241366\n",
      "2080/4000  loss= 2.126146227643924\n",
      "2090/4000  loss= 2.1235891547821786\n",
      "2100/4000  loss= 2.12109475999398\n",
      "2110/4000  loss= 2.118661020024501\n",
      "2120/4000  loss= 2.116285986010593\n",
      "2130/4000  loss= 2.113967780651974\n",
      "2140/4000  loss= 2.1117045954568425\n",
      "2150/4000  loss= 2.1094946880866132\n",
      "2160/4000  loss= 2.1073363798252656\n",
      "2170/4000  loss= 2.105228053104821\n",
      "2180/4000  loss= 2.103168149129605\n",
      "2190/4000  loss= 2.1011551655851965\n",
      "2200/4000  loss= 2.0991876544305295\n",
      "2210/4000  loss= 2.0972642197635265\n",
      "2220/4000  loss= 2.0953835157939436\n",
      "2230/4000  loss= 2.093544244873085\n",
      "2240/4000  loss= 2.091745155605755\n",
      "2250/4000  loss= 2.0899850410407916\n",
      "2260/4000  loss= 2.0882627369241664\n",
      "2270/4000  loss= 2.0865771200381222\n",
      "2280/4000  loss= 2.084927106564339\n",
      "2290/4000  loss= 2.0833116505723113\n",
      "2300/4000  loss= 2.081729742540494\n",
      "2310/4000  loss= 2.0801804079286113\n",
      "2320/4000  loss= 2.078662705818325\n",
      "2330/4000  loss= 2.077175727602733\n",
      "2340/4000  loss= 2.075718595740305\n",
      "2350/4000  loss= 2.0742904625677943\n",
      "2360/4000  loss= 2.0728905091347603\n",
      "2370/4000  loss= 2.0715179441040283\n",
      "2380/4000  loss= 2.0701720026819994\n",
      "2390/4000  loss= 2.068851945630655\n",
      "2400/4000  loss= 2.0675570582768708\n",
      "2410/4000  loss= 2.066286649584126\n",
      "2420/4000  loss= 2.0650400512674585\n",
      "2430/4000  loss= 2.063816616921563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440/4000  loss= 2.0626157212156295\n",
      "2450/4000  loss= 2.061436759098415\n",
      "2460/4000  loss= 2.0602791450435785\n",
      "2470/4000  loss= 2.0591423123270456\n",
      "2480/4000  loss= 2.0580257123317156\n",
      "2490/4000  loss= 2.0569288138852944\n",
      "2500/4000  loss= 2.0558511026211157\n",
      "2510/4000  loss= 2.054792080354497\n",
      "2520/4000  loss= 2.0537512645251645\n",
      "2530/4000  loss= 2.052728187607831\n",
      "2540/4000  loss= 2.0517223965827163\n",
      "2550/4000  loss= 2.050733452413028\n",
      "2560/4000  loss= 2.0497609295465837\n",
      "2570/4000  loss= 2.0488044154388003\n",
      "2580/4000  loss= 2.047863510104324\n",
      "2590/4000  loss= 2.0469378256660993\n",
      "2600/4000  loss= 2.0460269859395606\n",
      "2610/4000  loss= 2.045130626023447\n",
      "2620/4000  loss= 2.0442483919106986\n",
      "2630/4000  loss= 2.043379940120743\n",
      "2640/4000  loss= 2.0425249373382153\n",
      "2650/4000  loss= 2.041683060064419\n",
      "2660/4000  loss= 2.0408539942930233\n",
      "2670/4000  loss= 2.0400374351845114\n",
      "2680/4000  loss= 2.0392330867685278\n",
      "2690/4000  loss= 2.0384406616477273\n",
      "2700/4000  loss= 2.0376598807126625\n",
      "2710/4000  loss= 2.036890472882605\n",
      "2720/4000  loss= 2.0361321748212236\n",
      "2730/4000  loss= 2.035384730707982\n",
      "2740/4000  loss= 2.0346478919887296\n",
      "2750/4000  loss= 2.0339214171460216\n",
      "2760/4000  loss= 2.0332050714773224\n",
      "2770/4000  loss= 2.0324986268813494\n",
      "2780/4000  loss= 2.031801861645503\n",
      "2790/4000  loss= 2.0311145602530836\n",
      "2800/4000  loss= 2.030436513193129\n",
      "2810/4000  loss= 2.0297675167772713\n",
      "2820/4000  loss= 2.029107372960711\n",
      "2830/4000  loss= 2.0284558891743654\n",
      "2840/4000  loss= 2.027812878155455\n",
      "2850/4000  loss= 2.0271781577978754\n",
      "2860/4000  loss= 2.026551550995818\n",
      "2870/4000  loss= 2.025932885498192\n",
      "2880/4000  loss= 2.0253219937689746\n",
      "2890/4000  loss= 2.0247187128533106\n",
      "2900/4000  loss= 2.024122884240458\n",
      "2910/4000  loss= 2.0235343537422024\n",
      "2920/4000  loss= 2.022952971371037\n",
      "2930/4000  loss= 2.02237859122337\n",
      "2940/4000  loss= 2.0218110713657493\n",
      "2950/4000  loss= 2.0212502737248026\n",
      "2960/4000  loss= 2.0206960639850737\n",
      "2970/4000  loss= 2.020148311482912\n",
      "2980/4000  loss= 2.0196068891126293\n",
      "2990/4000  loss= 2.0190716732304907\n",
      "3000/4000  loss= 2.018542543561987\n",
      "3010/4000  loss= 2.0180193831146855\n",
      "3020/4000  loss= 2.017502078092207\n",
      "3030/4000  loss= 2.0169905178124052\n",
      "3040/4000  loss= 2.0164845946250916\n",
      "3050/4000  loss= 2.0159842038341753\n",
      "3060/4000  loss= 2.015489243626014\n",
      "3070/4000  loss= 2.014999614993041\n",
      "3080/4000  loss= 2.0145152216651785\n",
      "3090/4000  loss= 2.0140359700402857\n",
      "3100/4000  loss= 2.01356176911728\n",
      "3110/4000  loss= 2.013092530432661\n",
      "3120/4000  loss= 2.0126281679963776\n",
      "3130/4000  loss= 2.0121685982283246\n",
      "3140/4000  loss= 2.0117137399021043\n",
      "3150/4000  loss= 2.0112635140852175\n",
      "3160/4000  loss= 2.010817844082096\n",
      "3170/4000  loss= 2.01037665537696\n",
      "3180/4000  loss= 2.0099398755821962\n",
      "3190/4000  loss= 2.009507434382143\n",
      "3200/4000  loss= 2.0090792634804817\n",
      "3210/4000  loss= 2.0086552965530293\n",
      "3220/4000  loss= 2.008235469194015\n",
      "3230/4000  loss= 2.0078197188650346\n",
      "3240/4000  loss= 2.007407984848091\n",
      "3250/4000  loss= 2.0070002081965104\n",
      "3260/4000  loss= 2.006596331686825\n",
      "3270/4000  loss= 2.0061962997726157\n",
      "3280/4000  loss= 2.0058000585368836\n",
      "3290/4000  loss= 2.0054075556474786\n",
      "3300/4000  loss= 2.005018740310064\n",
      "3310/4000  loss= 2.00463356322044\n",
      "3320/4000  loss= 2.0042519765228164\n",
      "3330/4000  loss= 2.0038739337632023\n",
      "3340/4000  loss= 2.0034993898454236\n",
      "3350/4000  loss= 2.003128300986515\n",
      "3360/4000  loss= 2.0027606246710272\n",
      "3370/4000  loss= 2.0023963196081445\n",
      "3380/4000  loss= 2.002035345687567\n",
      "3390/4000  loss= 2.0016776639353773\n",
      "3400/4000  loss= 2.001323236469228\n",
      "3410/4000  loss= 2.000972026456872\n",
      "3420/4000  loss= 2.0006239980724243\n",
      "3430/4000  loss= 2.000279116450706\n",
      "3440/4000  loss= 1.999937347644218\n",
      "3450/4000  loss= 1.9995986585825367\n",
      "3460/4000  loss= 1.999263017027237\n",
      "3470/4000  loss= 1.9989303915293122\n",
      "3480/4000  loss= 1.9986007513873822\n",
      "3490/4000  loss= 1.9982740666051662\n",
      "3500/4000  loss= 1.997950307849177\n",
      "3510/4000  loss= 1.997629446407608\n",
      "3520/4000  loss= 1.997311454149259\n",
      "3530/4000  loss= 1.99699630348164\n",
      "3540/4000  loss= 1.9966839673120869\n",
      "3550/4000  loss= 1.9963744190074046\n",
      "3560/4000  loss= 1.9960676323547968\n",
      "3570/4000  loss= 1.9957635815231787\n",
      "3580/4000  loss= 1.9954622410257175\n",
      "3590/4000  loss= 1.9951635856827519\n",
      "3600/4000  loss= 1.994867590585224\n",
      "3610/4000  loss= 1.9945742310602104\n",
      "3620/4000  loss= 1.9942834826365092\n",
      "3630/4000  loss= 1.9939953210120174\n",
      "3640/4000  loss= 1.993709722021744\n",
      "3650/4000  loss= 1.9934266616075438\n",
      "3660/4000  loss= 1.9931461157902641\n",
      "3670/4000  loss= 1.992868060642903\n",
      "3680/4000  loss= 1.9925924722656525\n",
      "3690/4000  loss= 1.9923193267639503\n",
      "3700/4000  loss= 1.99204860023026\n",
      "3710/4000  loss= 1.9917802687276351\n",
      "3720/4000  loss= 1.9915143082782838\n",
      "3730/4000  loss= 1.991250694856245\n",
      "3740/4000  loss= 1.9909894043864795\n",
      "3750/4000  loss= 1.9907304127493761\n",
      "3760/4000  loss= 1.9904736957935942\n",
      "3770/4000  loss= 1.990219229356831\n",
      "3780/4000  loss= 1.9899669892972403\n",
      "3790/4000  loss= 1.9897169515354305\n",
      "3800/4000  loss= 1.9894690921090135\n",
      "3810/4000  loss= 1.989223387239999\n",
      "3820/4000  loss= 1.9889798134159367\n",
      "3830/4000  loss= 1.988738347483455\n",
      "3840/4000  loss= 1.9884989667536006\n",
      "3850/4000  loss= 1.9882616491164506\n",
      "3860/4000  loss= 1.9880263731610999\n",
      "3870/4000  loss= 1.9877931182938615\n",
      "3880/4000  loss= 1.9875618648485167\n",
      "3890/4000  loss= 1.98733259417972\n",
      "3900/4000  loss= 1.9871052887315135\n",
      "3910/4000  loss= 1.9868799320704662\n",
      "3920/4000  loss= 1.9866565088758108\n",
      "3930/4000  loss= 1.9864350048858472\n",
      "3940/4000  loss= 1.986215406798479\n",
      "3950/4000  loss= 1.985997702131432\n",
      "3960/4000  loss= 1.9857818790522832\n",
      "3970/4000  loss= 1.9855679261908563\n",
      "3980/4000  loss= 1.985355832447683\n",
      "3990/4000  loss= 1.9851455868129664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the training for 3 different network architectures: (4-5-3) (4-10-3) (4-20-3)\n",
    "\n",
    "# Plot the loss function over iterations\n",
    "\n",
    "loss_plot = []\n",
    "weights1 = []\n",
    "weights2 = []\n",
    "num_iters = 4000\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "# for hidden_nodes in num_hidden_nodes:\n",
    "weights1, weights2,weights3 = create_train_network(20, num_iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAJTCAYAAAC4pzoaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XuYZOddH/jvr6qn56IZaSTNaKybLcuWYxvbCCOMDV6H2FyMITFJeFiTDRjCrpIs3uWS3cRANpDnWW9YnmACIQuxscGEcDHBgCFOwBcWcBZfJN9lY0voYt0sje4jjebS3e/+UadnWqOZ0fTUqa7q7s/neZo6dc6p6t9b1SN/ec9537daawEAYPYMpl0AAAAnJ6gBAMwoQQ0AYEYJagAAM0pQAwCYUYIaAMCMEtQAAGaUoAYAMKMENQCAGTU37QL6smfPnnbFFVdMuwwAgKd0/fXX39da2/tU561JUKuqy5P8apJ9SVqSt7TWfraqfiLJ/5Rkf3fqj7bW3tO95keSfF+SxST/a2vtj073O6644opcd911E2oBAEB/quq2MzlvrXrUFpL8k9bax6pqV5Lrq+q93bGfaa3965UnV9Xzk7wuyZcluSTJ+6rqOa21xTWqFwBg6tbkHrXW2t2ttY912weSfC7Jpad5yWuT/GZr7XBr7ZYkNyV5yeQrBQCYHWs+mKCqrkjyFUk+3O16Q1V9qqreXlXnd/suTXL7ipfdkZMEu6q6tqquq6rr9u/ff+JhAIB1bU2DWlXtTPI7SX6wtfZIkl9I8qwkVye5O8lPr+b9Wmtvaa1d01q7Zu/ep7wfDwBgXVmzoFZVWzIKaf+xtfauJGmt3dNaW2ytLSV5a45f3rwzyeUrXn5Ztw8AYNNYk6BWVZXkbUk+11p784r9F6847W8n+Uy3/e4kr6uqrVX1zCRXJfnIWtQKADAr1mrU59cm+a4kn66qT3T7fjTJd1bV1RlN2XFrkn+YJK21G6rqnUk+m9GI0e834hMA2GzWJKi11j6YpE5y6D2nec2bkrxpYkUBAMw4S0gBAMwoQQ0AYEYJagAAM0pQAwCYUYIaAMCMEtQAAGaUoAYAMKMENQCAGSWoAQDMKEENAGBGCWoAADNKUAMAmFGCGgDAjBLUVqG1Nu0SAIBNRFA7Q/c8cigv+1cfyL/8gxty36OHp10OALAJCGpn6LHDC7n68t35tQ/dlr/1bz+Yew8cmnZJAMAGJ6idoSv37swvftdX5nf+8dfkvkeP5M1//IVplwQAbHCC2iq96LLd+btfeVl+7xN35uCRhWmXAwBsYILaWfibL7o4h44u5UM33z/tUgCADUxQOwtXP313BpV8/IsPTbsUAGADE9TOwo75uVy5d2c+/6UD0y4FANjABLWzdMWF5+S2+w9OuwwAYAMT1M7SFRfuyK33P2YSXABgYgS1s/S087bl8MJSHnncyE8AYDIEtbO0d9fWJMl+qxQAABMiqJ2lPTu7oHZAUAMAJkNQO0vLPWrW/QQAJkVQO0u7t29Jkjz0+NEpVwIAbFSC2lnatW0U1A4cEtQAgMkQ1M7Sti2DzA0qBw4Z9QkATIagdpaqKru2zelRAwAmRlAbw65tW/SoAQATI6iNYdSjJqgBAJMhqI1h59a5PCqoAQATIqiNYcf8MI8fXZx2GQDABiWojWHblmEOCWoAwIQIamPYvkWPGgAwOYLaGLZuGebQ0aVplwEAbFCC2hi2u/QJAEyQoDaGbVsGghoAMDGC2hi2bxlmYanl6KLLnwBA/wS1MWzbMkwSvWoAwEQIamPYNj8KakZ+AgCTIKiNYdvc6OM7bOQnADABgtoY5peD2oKgBgD0T1Abw/xw9PEZTAAATIKgNoblHjVBDQCYBEFtDFv0qAEAEySojWE5qLlHDQCYBEFtDPNzlSQ5utimXAkAsBEJamOYH47mUTuqRw0AmABBbQxbjvWoCWoAQP8EtTEs36N2RFADACZAUBvD8jxqR1z6BAAmQFAbw/HpOQwmAAD6J6iNwYS3AMAkCWpj2DI0mAAAmBxBbQwmvAUAJklQG4NF2QGASRLUxjAYVIaDEtQAgIkQ1MY0HFQWloz6BAD6J6iNaW5QWTQ9BwAwAYLamOb0qAEAEyKojWluOMiioAYATICgNib3qAEAkyKojWluUFlcMuoTAOifoDYmPWoAwKQIamMa9agJagBA/wS1MelRAwAmRVAb09xgYB41AGAiBLUxjXrUDCYAAPonqI1pbujSJwAwGYLamAwmAAAmRVAb09xgkAX3qAEAEyCojWmoRw0AmBBBbUyje9QMJgAA+ieojUmPGgAwKYLamOZMeAsATIigNiY9agDApAhqY5obDHJ00T1qAED/BLUx6VEDACZFUBuTlQkAgEkR1MY0NygT3gIAEyGojWk4qCw2QQ0A6J+gNqaqShPUAIAJENTGNCyDCQCAyRDUxmTUJwAwKYLamAZVkdMAgEkQ1MY0HESPGgAwEYLamEY9aoIaANA/QW1Mg4GgBgBMhqA2JqM+AYBJEdTGNOpRi7nUAIDeCWpjGlYliZGfAEDv1iSoVdXlVfUnVfXZqrqhqn6g239BVb23qm7sHs/v9ldV/VxV3VRVn6qqF69FnWdjMMpp7lMDAHq3Vj1qC0n+SWvt+UlemuT7q+r5Sd6Y5P2ttauSvL97niTfnOSq7ufaJL+wRnWu2qBLau5TAwD6tiZBrbV2d2vtY932gSSfS3JpktcmeUd32juSfFu3/dokv9pGPpRkd1VdvBa1rtZwsHzpU1ADAPq15veoVdUVSb4iyYeT7Gut3d0d+lKSfd32pUluX/GyO7p9J77XtVV1XVVdt3///onVfDrL96jpUQMA+ramQa2qdib5nSQ/2Fp7ZOWxNho2uaq001p7S2vtmtbaNXv37u2x0jO3fOlzaWkqvx4A2MDWLKhV1ZaMQtp/bK29q9t9z/Ilze7x3m7/nUkuX/Hyy7p9M2doMAEAMCFrNeqzkrwtyedaa29ecejdSV7fbb8+ye+v2P/d3ejPlyZ5eMUl0plybDCBoAYA9GxujX7P1yb5riSfrqpPdPt+NMlPJnlnVX1fktuSfEd37D1JXpPkpiQHk3zvGtW5aoPledTcowYA9GxNglpr7YNJ6hSHX3WS81uS759oUT0Z6lEDACbEygRjMuoTAJgUQW1My/eo6VADAPomqI1peQkpPWoAQN8EtTG5Rw0AmBRBbUxGfQIAkyKojUmPGgAwKYLamI73qE25EABgwxHUxjSwhBQAMCGC2piOXfp0jxoA0DNBbUzW+gQAJkVQG9PQqE8AYEIEtTEtX/qU0wCAvglqYyorEwAAEyKojenYpU/3qAEAPRPUxmTUJwAwKYLamIz6BAAmRVAb0/KlzyaoAQA9E9TGtLyE1KIlpACAnglqYxp0n6B71ACAvglqYzo+j5qgBgD0S1Ab07CM+gQAJkNQG9NAjxoAMCGC2pgGJrwFACZEUBvT0KhPAGBCBLUxLY/6XHKPGgDQM0FtTEMrEwAAEyKojcmoTwBgUgS1MZUlpACACRHUxnR8wtspFwIAbDiC2pi6nObSJwDQO0FtTCa8BQAmRVAbkwlvAYBJEdTGZMJbAGBSBLUxHZvwVo8aANAzQW1Mxy59GkwAAPRMUBvTsEzPAQBMhqA2plqensOlTwCgZ4LamKoqg7IyAQDQP0GtB4MqE94CAL0T1HowGJRLnwBA7wS1HgyrIqcBAH0T1HowKGt9AgD9E9R6MBiUCW8BgN4Jaj0YVJnwFgDonaDWg+GgTHgLAPROUOvBoEx4CwD0T1DrwaDKhLcAQO8EtR6Y8BYAmARBrQfDQWVxadpVAAAbjaDWg8HAWp8AQP8EtR4MyhJSAED/BLUeDMv0HABA/wS1HlTFhLcAQO8EtR4MLSEFAEyAoNYD03MAAJMgqPVgUHrUAID+CWo9GAxiMAEA0DtBrQdDlz4BgAkQ1HowMJgAAJgAQa0H7lEDACZBUOvBsCpL1voEAHomqPWgKpaQAgB6J6j1YDgoi7IDAL0T1HpgwlsAYBIEtR4MBpVFOQ0A6Jmg1oNhxaVPAKB3gloPXPoEACZBUOvBaMLbaVcBAGw0gloPBpUsSWoAQM8EtR4MLSEFAEyAoNaDqjLhLQDQO0GtB8OqyGkAQN8EtR4MKkZ9AgC9E9R6MBiYngMA6J+g1oPRpU9BDQDol6DWg4HBBADABAhqPTDhLQAwCYJaD0x4CwBMgqDWAxPeAgCTIKj1wKLsAMAkCGo9GJR71ACA/glqPRhUXPoEAHonqPVgaMJbAGACBLUeDAbW+gQA+ieo9WBQMeEtANA7Qa0HwzI9BwDQP0GtB1WjS5/W+wQA+iSo9WA4qCQxRQcA0CtBrQddTjPyEwDolaDWg8GxHjVBDQDoj6DWg2EJagBA/wS1Hgy6oObSJwDQJ0GtBwODCQCACRDUerA8mGBJUgMAerQmQa2q3l5V91bVZ1bs+4mqurOqPtH9vGbFsR+pqpuq6vNV9U1rUeM4hgYTAAATsFY9ar+S5NUn2f8zrbWru5/3JElVPT/J65J8Wfea/6eqhmtU51mp5XvUBDUAoEdrEtRaa3+W5IEzPP21SX6ztXa4tXZLkpuSvGRixfVgedSnnAYA9Gna96i9oao+1V0aPb/bd2mS21ecc0e370mq6tqquq6qrtu/f/+kaz0lE94CAJMwzaD2C0meleTqJHcn+enVvkFr7S2ttWtaa9fs3bu37/rO2PKoT0ENAOjT1IJaa+2e1tpia20pyVtz/PLmnUkuX3HqZd2+meXSJwAwCVMLalV18YqnfzvJ8ojQdyd5XVVtrapnJrkqyUfWur7VGHSfosEEAECf5tbil1TVbyT5uiR7quqOJD+e5Ouq6uokLcmtSf5hkrTWbqiqdyb5bJKFJN/fWltcizrP1sASUgDABKxJUGutfedJdr/tNOe/KcmbJldRv44FNfeoAQA9mvaozw1haAkpAGACBLUemJ4DAJgEQa0H7lEDACZBUOuBoAYATIKg1oOhCW8BgAkQ1HowMJgAAJgAQa0Hy4MJXPoEAPokqPVgaB41AGACBLUeVBfULCEFAPRJUOvB8mACOQ0A6JOg1gMT3gIAkyCo9WB51KdLnwBAnwS1HiwPJmiCGgDQI0GtB8srEywuTbkQAGBDEdR6MOg+RfOoAQB9EtR6MDCPGgAwAYJaD4aWkAIAJkBQ68Gx6Tlc+gQAeiSo9WBg1CcAMAGCWg+Oj/oU1ACA/ghqPVi+R01QAwD6JKj1YGCtTwBgAgS1HhhMAABMgqDWg+UlpEx4CwD0SVDrQZnwFgCYAEGtBya8BQAmQVDrwbF71CQ1AKBHgloPBgP3qAEA/RPUejAwmAAAmABBrQfDYysTTLkQAGBDEdR6MOg+RT1qAECfBLUeDEzPAQBMgKDWg+MT3k65EABgQxHUelCWkAIAJkBQ60FVZVBJE9QAgB4Jaj0ZVJnwFgDolaDWk8GgXPoEAHolqPVkWBU5DQDok6DWk0FZ6xMA6Jeg1pPBoEx4CwD0SlDryaDKhLcAQK8EtZ4MB2XCWwCgV4JaTwZlwlsAoF+CWk8GVSa8BQB6Jaj1xIS3AEDfBLWeDAeVxaVpVwEAbCSCWk8GA2t9AgD9OuOgVlU/XFVXd9svraovVtUtVfWyyZW3fgzKElIAQL9W06P2Q0lu6bb/VZI3J/k/k/ybvotaj4Zleg4AoF9zqzj3vNbaw1W1K8mXJ/n61tpiVf30hGpbV6piwlsAoFerCWq3V9XXJPmyJH/WhbRzkyxOprT1ZTSYQFADAPqzmqD2vyf5T0mOJPm73b5vTfKRvotaj4aDgXvUAIBenXFQa629J8klJ+z+7e5n05vTowYA9Gw1oz6fX1X7uu2dVfUvk/xoki2TKm49GQ4qC4IaANCj1Yz6/I0ku7vtf53kFUlemuTf913UejTqUTPjLQDQn9Xco3ZFa+3zVVVJ/k6S5yd5PMen7NjUhoPKwqIeNQCgP6sJaoe6qTmen+SLrbX7qmouybbJlLa+zA0rh4/qUQMA+rOaoPbrST6QZFeSn+/2vTh61JKMRn0uLJmpBADoz2pGff5QVX1jkqOttT/pdi9ltGLBpmfUJwDQt9X0qKW19sdV9fRufc87W2vXTaiudceoTwCgb6uZnuPiqvrTJDcmeVeSm6rqT6vqxLnVNiWjPgGAvq1meo5fSPLJJBe01i5Ocn6STyT5xUkUtt7oUQMA+raaS58vT3Jxa+1okrTWHquqf5rkzolUts64Rw0A6NtqetQezGhqjpX+WpKH+itn/RoOBuZRAwB6tZoetZ9K8r6qeluS25I8I8n3Jvk/JlHYeqNHDQDo2xn3qLXW3prkv0+yJ8nf7B7/XpLLJlPa+jJwjxoA0LPVTs/xgYwmvU2SVNXWJH+c5F/0XNe6Y9QnANC31dyjdirVw3use0Z9AgB96yOoSScZ9agtCWoAQI+e8tJnVb3yNIfne6xlXRsO9agBAP06k3vU3vYUx7/YRyHrnVGfAEDfnjKotdaeuRaFrHfDwSALSy2ttVS5bQ8AGF8f96iRUY9akuhUAwD6Iqj1ZNgFtQVTdAAAPRHUerLco+Y+NQCgL4JaT473qAlqAEA/BLWeHOtRszA7ANATQa0nw+Hoo9SjBgD0RVDriXvUAIC+CWo9MeoTAOiboNYTPWoAQN8EtZ4Y9QkA9E1Q68lQjxoA0DNBrSfLlz4XTM8BAPREUOvJcDD6KPWoAQB9EdR6cmwwQRPUAIB+CGo9OX6Pmuk5AIB+CGo9cY8aANA3Qa0nRn0CAH0T1HoyNzSPGgDQL0GtJ0Z9AgB9E9R6MmdlAgCgZ4JaT4z6BAD6Jqj1RI8aANC3NQlqVfX2qrq3qj6zYt8FVfXeqrqxezy/219V9XNVdVNVfaqqXrwWNY7LqE8AoG9r1aP2K0lefcK+NyZ5f2vtqiTv754nyTcnuar7uTbJL6xRjWOZ6wYTmEcNAOjLmgS11tqfJXnghN2vTfKObvsdSb5txf5fbSMfSrK7qi5eizrHMRzqUQMA+jXNe9T2tdbu7ra/lGRft31pkttXnHdHt+9Jquraqrquqq7bv3//5Co9A+5RAwD6NhODCVprLcmqE05r7S2ttWtaa9fs3bt3ApWdOaM+AYC+TTOo3bN8SbN7vLfbf2eSy1ecd1m3b6bpUQMA+jbNoPbuJK/vtl+f5PdX7P/ubvTnS5M8vOIS6cwaGPUJAPRsbi1+SVX9RpKvS7Knqu5I8uNJfjLJO6vq+5LcluQ7utPfk+Q1SW5KcjDJ965FjePSowYA9G1Nglpr7TtPcehVJzm3Jfn+yVbUP/OoAQB9m4nBBBvBnEXZAYCeCWo96TrUXPoEAHojqPWkqjI3KNNzAAC9EdR6NByUHjUAoDeCWo/mBpVFa30CAD0R1HqkRw0A6JOg1qO54cCoTwCgN4Jaj/SoAQB9EtR6ZNQnANAnQa1HetQAgD4Jaj0a9agJagBAPwS1HulRAwD6JKj1aG4wMI8aANAbQa1Hox41gwkAgH4Iaj2anxvk8IKgBgD0Q1Dr0fxwkKOLghoA0A9BrUfzc4Mc0aMGAPREUOvR/NwgR/SoAQA9EdR6ND/UowYA9EdQ69EWlz4BgB4Jaj0aDSYwjxoA0A9BrUem5wAA+iSo9Wjr3CBHFhanXQYAsEEIaj3aMiyjPgGA3ghqPZqfc48aANAfQa1H88NhFpdaFpeENQBgfIJaj+bnRh+nKToAgD4Iaj3a2gW1wwYUAAA9ENR6tHPbXJLkwKGFKVcCAGwEglqPztu+JUny8ONHp1wJALARCGo9OnfbKKg9ckhQAwDGJ6j16Nzto0ufj+hRAwB6IKj1aPnS5yOPu0cNABifoNaj5aD24MEjU64EANgIBLUe7dw6l51b53L3w4emXQoAsAEIaj2qqlyye1vueujxaZcCAGwAglrPLt29PXc9LKgBAOMT1Hp2ye7tueshlz4BgPEJaj27ZPf2PPDYkTx+xDJSAMB4BLWeXbp7e5K4/AkAjE1Q69kly0HNgAIAYEyCWs8u2b0tSXLng4IaADAeQa1n+87dlkHpUQMAxieo9WzLcJB9527LnUZ+AgBjEtQmYDRFhx41AGA8gtoEXGLSWwCgB4LaBFy6e3vufuhQlpbatEsBANYxQW0CLtm9LUcWl3LfY4enXQoAsI4JahOw79zRFB33PiKoAQBnT1CbgGNB7YCRnwDA2RPUJuCiXVuTJPfoUQMAxiCoTcDeY0FNjxoAcPYEtQnYMhxkz8753HtAjxoAcPYEtQm5aNe23KtHDQAYg6A2IRedu9U9agDAWAS1Cdm3a5t71ACAsQhqE7Lv3K2579HDWbQ6AQBwlgS1Cbno3G1Zasn9j7r8CQCcHUFtQsylBgCMS1CbkOXVCdynBgCcLUFtQo4FNctIAQBnSVCbkD0751NlYXYA4OwJahMyNxzkwnO2uvQJAJw1QW2C9u4aTdEBAHA2BLUJ2rNzPvsfPTLtMgCAdUpQm6C9O7fmPguzAwBnSVCboD3dpc/WrE4AAKyeoDZBe3bO5/DCUh49vDDtUgCAdUhQm6A9O0erE9znPjUA4CwIahN0PKi5Tw0AWD1BbYKOBTUDCgCAsyCoTdCeXfNJ9KgBAGdHUJugC3aMlpEylxoAcDYEtQmaGw5ywY55PWoAwFkR1CZsj0lvAYCzJKhN2J5detQAgLMjqE3Ynp1bzaMGAJwVQW3CRkFNjxoAsHqC2oTt2bk1B48s5uARy0gBAKsjqE3Ynp3dXGoHXP4EAFZHUJuwPbtGqxPsd/kTAFglQW3C9lrvEwA4S4LahC2v93m/kZ8AwCoJahN24U7rfQIAZ0dQm7Atw0F279giqAEAqyaorQFzqQEAZ0NQWwN7ds6bngMAWDVBbQ3oUQMAzoagtgb27NxqHjUAYNUEtTWwd9fWHDi0kENHF6ddCgCwjghqa2B5Gan7H3OfGgBw5gS1NbA86e19B1z+BADOnKC2BvZYRgoAOAuC2hpYXphdUAMAVmNu2gVU1a1JDiRZTLLQWrumqi5I8ltJrkhya5LvaK09OK0ax3XhOcvLSLlHDQA4c7PSo/Y3WmtXt9au6Z6/Mcn7W2tXJXl/93zd2rZlmF3b5rLfPWoAwCrMSlA70WuTvKPbfkeSb5tiLb3Ya9JbAGCVZiGotSR/XFXXV9W13b59rbW7u+0vJdl3shdW1bVVdV1VXbd///61qPWsWZ0AAFitqd+jluTlrbU7q+qiJO+tqr9cebC11qqqneyFrbW3JHlLklxzzTUnPWdW7Nk1ny/c8+i0ywAA1pGp96i11u7sHu9N8rtJXpLknqq6OEm6x3unV2E/9u7cmnseOTTtMgCAdWSqQa2qzqmqXcvbSb4xyWeSvDvJ67vTXp/k96dTYX8uO39HDhxayMOPH512KQDAOjHtS5/7kvxuVS3X8uuttf9aVR9N8s6q+r4ktyX5jinW2IvLL9ieJLn9gYM579LzplwNALAeTDWotdZuTvLlJ9l/f5JXrX1Fk3PZ+TuSJHc8eDAvENQAgDMw9XvUNovLu6B2+wOPT7kSAGC9ENTWyHk7tmTXtrnc/uDBaZcCAKwTgtoauvz8Hbn9AUENADgzgtoaevoFO3Lb/YIaAHBmBLU1dNW+nbntgYM5vLA47VIAgHVAUFtDz75oZxaXWm69T68aAPDUBLU1dNVFu5IkN957YMqVAADrgaC2hq7ce04GldxozU8A4AwIamto25Zhnn7Bjtx0r6AGADw1QW2NPfuiXfn8PS59AgBPTVBbY192ybm5ef+jOXhkYdqlAAAzTlBbYy+49LwsteRzdz8y7VIAgBknqK2xF3YLsn/6joenXAkAMOsEtTW279yt2bNzPp+5S48aAHB6gtoaq6q84NLz8pk79agBAKcnqE3BCy45Lzfe+2gOHbWUFABwaoLaFLzg0vOyuNRyg8ufAMBpCGpT8OJn7E6SfOy2B6dcCQAwywS1Kbho17Y8/YId+eitD0y7FABghglqU3LNFefn+tseTGtt2qUAADNKUJuSa55xQe5/7Ehuvf/gtEsBAGaUoDYlX3XF+UmS61z+BABOQVCbkmft3ZndO7bkI7cIagDAyQlqUzIYVL7mWRfmz2+8z31qAMBJCWpT9Iqr9uZLjxzKjfc+Ou1SAIAZJKhN0SueszdJ8mdf2D/lSgCAWSSoTdElu7fn2RftzJ8KagDASQhqU/aKq/bmI7c8YN1PAOBJBLUpe8Vz9uTwwlL+4ub7p10KADBjBLUpe+mVF2b7lmE+8Ll7p10KADBjBLUp27ZlmJdftScf+Mt7TdMBADyBoDYDXvXci3LnQ4/nL790YNqlAAAzRFCbAa987kVJkvd/7p4pVwIAzBJBbQZcdO62fPll5+X9f+k+NQDgOEFtRrzyufvyidsfyn2PHp52KQDAjBDUZsSrnndRWks+oFcNAOgIajPiyy45N087d5tpOgCAYwS1GVFVeeXzLsqf37g/hxesUgAACGoz5eufd1EeO7KYD9/8wLRLAQBmgKA2Q77mWXuybcvANB0AQBJBbaZs2zLMy5+9J+/7nFUKAABBbea86nn7cudDj+cL9zw67VIAgCkT1GbM8ioF73P5EwA2PUFtxuw7d1teeOl57lMDAAS1WfSq512Uj9/+UO63SgEAbGqC2gx61XP3pbXkTz6/f9qlAABTJKjNoBdcem72nbvV5U8A2OQEtRlUVXnlc/flz76wP0cWlqZdDgAwJYLajHrVc7tVCm65f9qlAABTIqjNqK999p5snRvk/RZpB4BNS1CbUdvnR6sUvP8v77FKAQBsUoLaDHvl8y7K7Q88nhvvtUoBAGxGgtoMe9Vz9yWxSgEAbFaC2gx72nnb8qLLzssffeZL0y4FAJgCQW3GfcsLL84n73g4X7z/4LRLAQDWmKA2417zwouTJP/503dPuRIAYK0JajPu8gt25OrLd+cPP3XXtEsBANaYoLYOfOuLLs4Ndz2SW+57bNqlAABrSFBbB45d/tSrBgCbiqC2Dlyye3uuecb5+YNP3m3yWwDYRAS1deK1X3FpPn/Pgdxw1yPTLgUAWCOC2jrxt778kmydG+Sd190+7VL9O/YLAAASWUlEQVQAgDUiqK0T523fkle/4Gn5vY/fmUNHF6ddDgCwBgS1deQ7rrk8jxxayHs/a0kpANgMBLV15GVXXphLd2/Pb33U5U8A2AwEtXVkMKj8va9+ej540335wj0Hpl0OADBhgto6850veXq2zg3yy//tlmmXAgBMmKC2zlxwznz+zosvy7s+dmceeOzItMsBACZIUFuHvu/lV+TwwlL+w1/cNu1SAIAJEtTWoWdftCvf8Px9+aUP3pyHDx6ddjkAwIQIauvUD3/Dc3Lg0ELe+uc3T7sUAGBCBLV16nkXn5tvfdHFeft/uyX7DxyedjkAwAQIauvYD3/Dc3J0cSn/6r98btqlAAATIKitY1fu3ZlrX3Fl3vWxO/MXf3X/tMsBAHomqK1zb/gbV+Wy87fnx3730zl4ZGHa5QAAPRLU1rnt88P81N99UW65/7H8xLtvmHY5AECPBLUN4GuevSdv+BvPzjuvuyO/c/0d0y4HAOiJoLZB/MCrrspLr7wgb3zXp/L//dV90y4HAOiBoLZBzA0H+fd//5pcceE5+Ye/en0+/sUHp10SADAmQW0DOW/HlvzKP3hJzj9nPn//lz6sZw0A1jlBbYO5dPf2/PY/elku2b093/P2j+bXPnRbWmvTLgsAOAuC2ga079xt+e1/9LK87FkX5p//3mfyQ7/1iTx08Mi0ywIAVklQ26B275jPL3/PV+WHvv45+cNP3Z2vf/Of5vc+fmeWlvSuAcB6IahtYINB5Qe+/qq8+w0vzyW7t+cHf+sT+ZZ/+8G877P3CGwAsA7URrl/6ZprrmnXXXfdtMuYWYtLLX/wybvy5vd+IV984GCeueec/P2XPiN/5ysuzfnnzE+7PADYVKrq+tbaNU95nqC2uRxdXMp//tTd+Q8fui3X3/ZghoPK1zzrwnzLCy/ONzx/Xy7cuXXaJQLAhieo8ZQ+e9cj+YNP3ZX3fPru3Hb/wSTJ8y8+Ny+/ak++6ooL8sJLz8u+c7emqqZcKQBsLIIaZ6y1lhvueiR/+oX9+eCN9+X62x7MkcWlJMmenVvzwkvPzVX7duXKPefkyr0788w952TPznkBDgDOkqDGWXv8yGI+e/fD+fQdD+fTdz6SG+56ODff91iOLCwdO2fX1rlcvHtbLj5vey7ZvS1PO3d7Lt69LU87d1v27NyaC3fO5/wd85mfM14FAE50pkFtbi2KYX3ZPj/MVz7jgnzlMy44tm9xqeWuhx7Pzfc9llv2P5pb7z+Yux56PF965FBuuOuR3Pfo4ZO+165tc7nwnPlccM58Ljhnay44Z0t2bduSc7dtya5tc93PlpzbPa7cJ+QBsNkJapyR4aBy+QU7cvkFO/LXn7P3SccPLyzm3kcO5+6HD+X+Rw/n/seO5IHuZ7R9OHc8eDCfvvNIDhxayMEji0/5O+eHg2yfH2b7lmF2zA+zfX75cS47Trav2942N8zWLYNsPfbYbc8Nsm3L8e3l4/PDQQYDl3EBmD2CGr3YOjc8FuTOxMLiUh49vJADhxby8ONHc+DQQg4ceuLjY0cW8/iRUag7eHQxjx9ZzMEjC3n44JHcfWQxB48s5tDR0ePjR586+J3O/LALdE8IeMuBbpCtW45vb9syPPa4HPxWPi4f37ryvO49n/DauUHmhnoNATg1QY2pmBsOsnvHfHbvmM/lPbzf0lLLoYXj4e3wwlIOH13K4YVue2Eph48e3z52zsJid96Kc0/yukceP5pDRxdzZMVrDx1dzKGFpSyOMXnwcFDZdkL4mz+DEPiEx5Ps29YFxSe8djkszg31IAKsE4IaG8JgUNkxP5cd82v/J72wuJRDXaA7tBzkji7l0MLKxxXhrguCKx9Xhr/DK97joYNHnnjeivccZxzQ8R7E45eEn9hT+ORew+WQd2KIPH0P4/HtLcMyUhhglWY6qFXVq5P8bJJhkl9qrf3klEuCJ5kbDrJzOMjOrWv3z6m1lqOLo17E5VB3Yvg7XQg88bzDJ5z3yKGjT36Po0vHpm05G4PKScPg1q4H8PQB8Mnnnnhsfm6QLcPRPYdb5mq0Pdc9Hw4y1IsIrEMzG9Sqapjk3yX5hiR3JPloVb27tfbZ6VYG01dVmZ+rzM8Ncu62LWv2e5eW2pND33LgW9GjePzy85ND4/FewSe+z8l6D5eP9zGL0KDypPB2LNANjwe9LcPRvq3Hng8yN6zMDSrDwaB7HP3MPeFxdN6gVuwfPvH4cJAnvMfK9xrWqMdxOKgMavQdDyoZ1Og9a3l7sLxv+Zzj59WK80/6Hitee6rzgdkys0EtyUuS3NRauzlJquo3k7w2iaAGUzIY1Ggk7vxwzX5nay1HFpee1Pt3YgBcWFrKkcWWIwtLObo4+hltn7Cvezy6MHrfI4tLOXrs+OjcA0cX8sDiE/cttZaFpZbFpZaFxdG9iQtLLUtd7+ZGUZVURqGtjj0f7Vx+noz2nXju8jlZ3neS91o+o1a834nv9YRaTnL82BmnqHVl3nzCseW2nNDeFW/35A/jFMdO97o649edcPS073nq1z2xvSe+ZZ3y2BPf44T3PMX7P/nYmb8up6nl9L/vzNqwqnOe/G0/wX931Z687iVPf+o3WgOzHNQuTXL7iud3JPnqlSdU1bVJrk2Spz99Nj5QoF9V1Y3AHSZZu97D1VpaWhHklpaytJQsLB0PdCsfl885cd9Sa2ktWWotS91jay1LS8f3tRXHTnl+O+H8pZXHn/r81pKW5ccce54uj472Pfn4yp7P1tqTjrVjx0bv0tqTj7djv2O0oz3pvZ74/ln5+uU6V5z7hN91wne2csL3Jx/LaY6dOpg/8XXt1MdOeIuV5z752Ip97dj/OaPXnarmJx479etOPHj6152mlgl8nk91/inPeepT8px9u87grLUxy0HtKbXW3pLkLcloZYIplwNsYoNBZf7YfXBr1+MIbGyzPInTnckTZm64rNsHALApzHJQ+2iSq6rqmVU1n+R1Sd495ZoAANbMzF76bK0tVNUbkvxRRtcR3t5au2HKZQEArJmZDWpJ0lp7T5L3TLsOAIBpmOVLnwAAm5qgBgAwowQ1AIAZJagBAMwoQQ0AYEYJagAAM0pQAwCYUYIaAMCMEtQAAGaUoAYAMKMENQCAGSWoAQDMKEENAGBGCWoAADNKUAMAmFGCGgDAjBLUAABmlKAGADCjBDUAgBlVrbVp19CLqtqf5LY1+FV7kty3Br9nFmn75rWZ27+Z255s7vZv5rYnm7v9a9H2Z7TW9j7VSRsmqK2VqrqutXbNtOuYBm3fnG1PNnf7N3Pbk83d/s3c9mRzt3+W2u7SJwDAjBLUAABmlKC2em+ZdgFTpO2b12Zu/2Zue7K527+Z255s7vbPTNvdowYAMKP0qAEAzChB7QxV1aur6vNVdVNVvXHa9UxCVd1aVZ+uqk9U1XXdvguq6r1VdWP3eH63v6rq57rP41NV9eLpVr96VfX2qrq3qj6zYt+q21tVr+/Ov7GqXj+NtqzWKdr+E1V1Z/f9f6KqXrPi2I90bf98VX3Tiv3r7t9FVV1eVX9SVZ+tqhuq6ge6/Zvluz9V+zf8919V26rqI1X1ya7t/7Lb/8yq+nDXjt+qqvlu/9bu+U3d8StWvNdJP5NZdpr2/0pV3bLiu7+627+h/vaTpKqGVfXxqvrD7vnsf/etNT9P8ZNkmOSvklyZZD7JJ5M8f9p1TaCdtybZc8K+n0ryxm77jUn+7277NUn+S5JK8tIkH552/WfR3lckeXGSz5xte5NckOTm7vH8bvv8abftLNv+E0n+t5Oc+/zub35rkmd2/xaG6/XfRZKLk7y4296V5AtdGzfLd3+q9m/477/7Dnd221uSfLj7Tt+Z5HXd/l9M8o+77f85yS92269L8lun+0ym3b4x2v8rSb79JOdvqL/9rvYfTvLrSf6wez7z370etTPzkiQ3tdZubq0dSfKbSV475ZrWymuTvKPbfkeSb1ux/1fbyIeS7K6qi6dR4Nlqrf1ZkgdO2L3a9n5Tkve21h5orT2Y5L1JXj356sdzirafymuT/GZr7XBr7ZYkN2X0b2Jd/rtord3dWvtYt30gyeeSXJrN892fqv2nsmG+/+47fLR7uqX7aUlemeQ/dftP/O6X/yb+U5JXVVXl1J/JTDtN+09lQ/3tV9VlSb4lyS91zyvr4LsX1M7MpUluX/H8jpz+P2zrVUvyx1V1fVVd2+3b11q7u9v+UpJ93fZG/UxW296N9jm8obvE8fblS3/ZwG3vLmd8RUY9C5vuuz+h/ckm+P67S1+fSHJvRgHjr5I81Fpb6E5Z2Y5jbeyOP5zkwqzTtidPbn9rbfm7f1P33f9MVW3t9m2o7z7Jv0nyT5Msdc8vzDr47gU1Vnp5a+3FSb45yfdX1StWHmyjft9NM0x4s7U3yS8keVaSq5PcneSnp1vOZFXVziS/k+QHW2uPrDy2Gb77k7R/U3z/rbXF1trVSS7LqCfkuVMuaU2d2P6qekGSH8noc/iqjC5n/rMpljgRVfWtSe5trV0/7VpWS1A7M3cmuXzF88u6fRtKa+3O7vHeJL+b0X/E7lm+pNk93tudvlE/k9W2d8N8Dq21e7r/iC8leWuOd+dvuLZX1ZaMQsp/bK29q9u9ab77k7V/M33/SdJaeyjJnyR5WUaX9Oa6QyvbcayN3fHzktyfdd725Antf3V3Oby11g4n+eVszO/+a5P8raq6NaPL9K9M8rNZB9+9oHZmPprkqm50yHxGNxa+e8o19aqqzqmqXcvbSb4xyWcyaufyiJ7XJ/n9bvvdSb67GxX00iQPr7hstJ6ttr1/lOQbq+r87lLRN3b71p0T7jH82xl9/8mo7a/rRkE9M8lVST6SdfrvorvP5G1JPtdae/OKQ5viuz9V+zfD919Ve6tqd7e9Pck3ZHSP3p8k+fbutBO/++W/iW9P8oGut/VUn8lMO0X7/3LF/4NSGd2jtfK73xB/+621H2mtXdZauyKjv9UPtNb+h6yH737c0Qib5Sej0S9fyOh+hh+bdj0TaN+VGY1k+WSSG5bbmNE1+fcnuTHJ+5Jc0O2vJP+u+zw+neSaabfhLNr8Gxld4jma0X0G33c27U3yDzK6ofSmJN877XaN0fb/0LXtUxn9x+jiFef/WNf2zyf55hX7192/iyQvz+iy5qeSfKL7ec0m+u5P1f4N//0neVGSj3dt/EySf9HtvzKj/7G9KclvJ9na7d/WPb+pO37lU30ms/xzmvZ/oPvuP5Pk13J8ZOiG+ttfUfvX5fioz5n/7q1MAAAwo1z6BACYUYIaAMCMEtQAAGaUoAYAMKMENQCAGSWoAYyhqh6tqiunXQewMQlqwLpWVbdW1ddX1fdU1Qcn/Lv+36r6H1fua63tbK3dPMnfC2xeghpAji0TAzBTBDVgI3hekl9M8rLuUuRDSdIt8/Kvq+qLVXVPVf1it3ROqurrquqOqvpnVfWlJL/cLYnzh1W1v6oe7LYv685/U5L/LsnPd7/j57v9raqe3W2fV1W/2r3+tqr651U16I59T1V9sKvnwaq6paq+ec0/KWBdEdSAjeBzSf5Rkr/oLkXu7vb/ZJLnJLk6ybOTXJrkX6x43dOSXJDkGUmuzei/ib/cPX96kseT/HyStNZ+LMmfJ3lD9zvecJI6/m1GizdfmeSvJ/nuJN+74vhXZ7TszJ4kP5Xkbd36igAnJagBG1IXgK5N8kOttQdaaweS/F8ZLci8bCnJj7fWDrfWHm+t3d9a+53W2sHu/DdlFLjO5PcNu/f+kdbagdbarUl+Osl3rTjtttbaW1tri0nekeTiJPvGbCqwgbknA9io9ibZkeT6FZ1WlWS44pz9rbVDxw5W7UjyM0leneT8bveuqhp24ep09iTZkuS2Fftuy6gXb9mXljdaawe7unaeaYOAzUePGrBRtBOe35fRpcsva63t7n7Oa63tPM1r/kmSv5bkq1tr5yZ5Rbe/TnH+ib/vaEaXTZc9Pcmdq2gDwBMIasBGcU+Sy6pqPklaa0tJ3prkZ6rqoiSpqkur6ptO8x67Mgp3D1XVBUl+/CS/46RzpnU9bu9M8qaq2lVVz0jyw0l+bYw2AZucoAZsFB9IckOSL1XVfd2+f5bkpiQfqqpHkrwvox6zU/k3SbZn1Dv2oST/9YTjP5vk27tRmz93ktf/L0keS3Jzkg8m+fUkbz+75gAk1drpevIBAJgWPWoAADNKUAMAmFGCGgDAjBLUAABmlKAGADCjBDUAgBklqAEAzChBDQBgRglqAAAz6v8Hs8FTcJDOty4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(range(num_iters), loss_plot)\n",
    "    \n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_value(test_X,test_y):\n",
    "    np.random.seed(100)\n",
    "    X=tf.placeholder(shape=(30,4),dtype=tf.float64,name=\"X\")\n",
    "    y=tf.placeholder(shape=(30,3),dtype=tf.float64,name=\"y\")\n",
    "    \n",
    "    w1=weights1\n",
    "\n",
    "    w2=weights2\n",
    "\n",
    "    w3=weights3\n",
    "\n",
    "    \n",
    "    h1=tf.sigmoid(tf.matmul(X,w1))\n",
    "    h2=tf.sigmoid(tf.matmul(h1,w2))\n",
    "    y_est=tf.sigmoid(tf.matmul(h2,w3))\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        y_predict=sess.run(y_est,feed_dict={X:test_X,y:test_y})\n",
    "       \n",
    "        \n",
    "    print(f\"Predicted = {np.argmax(y_predict,axis=1)}\")\n",
    "    print(f\"Actual = {np.argmax(test_y.values,axis=1)}\")\n",
    "    count =0\n",
    "    for pred,actual in zip(np.argmax(y_predict,axis=1),np.argmax(test_y.values,axis=1)):\n",
    "        if(pred==actual):\n",
    "            count+=1\n",
    "    \n",
    "    accuracy=(count/30)*100\n",
    "    print(f\"Successful identification = {count}\")\n",
    "    print(f\"Accuracy = {accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted = [1 2 0 1 1 1 0 2 1 2 2 0 2 1 1 0 1 0 0 2 0 1 2 2 1 1 0 1 2 1]\n",
      "Actual = [1 2 0 1 1 1 0 2 1 2 2 0 2 1 1 0 1 0 0 2 0 1 2 1 1 1 0 1 2 1]\n",
      "Successful identification = 29\n",
      "Accuracy = 96.66666666666667\n"
     ]
    }
   ],
   "source": [
    "predict_value(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
